from llama_index.core import VectorStoreIndex
from llama_index.embeddings.openai import OpenAIEmbedding
from llama_index.llms.openai import OpenAI
from lunarcalendar import Converter, Solar
from datetime import datetime

import os
from dotenv import load_dotenv
from llama_index.core import Settings

from llama_index.core.tools import FunctionTool
from enum import Enum
from pydantic import BaseModel, Field
from typing import List
from llama_index.core.program import FunctionCallingProgram
from llama_index.core import (
    SimpleDirectoryReader,
    VectorStoreIndex,
    StorageContext,
    load_index_from_storage,
)
from llama_index.core import Settings
from llama_index.core.tools import FunctionTool
from llama_index.core.agent import ReActAgent
from llama_index.core.memory import ChatMemoryBuffer, ChatSummaryMemoryBuffer
import json
import tiktoken
from models import ChatHistory, UserSession, Session as DBSession

MODEL_NAME = "gpt-4o-mini"
MODEL_EMBEDDING_NAME = "text-embedding-3-small"

load_dotenv()  # take environment variables from .env.
os.environ["OPENAI_API_KEY"] = os.getenv('OPENAI_API_KEY')

embed_model = OpenAIEmbedding(model=MODEL_EMBEDDING_NAME, dimensions=1536)
llm = OpenAI(model=MODEL_NAME)


def convert_to_lunar(year, month, day):
    solar = Solar(year, month, day)
    lunar = Converter.Solar2Lunar(solar)
    return lunar


def get_thien_can_dia_chi(year):
    can = ['Gi√°p', '·∫§t', 'B√≠nh', 'ƒêinh', 'M·∫≠u', 'K·ª∑', 'Canh', 'T√¢n', 'Nh√¢m', 'Qu√Ω']
    chi = ['T√Ω', 'S·ª≠u', 'D·∫ßn', 'M√£o', 'Th√¨n', 'T·ªµ', 'Ng·ªç', 'M√πi', 'Th√¢n', 'D·∫≠u', 'Tu·∫•t', 'H·ª£i']
    can_index = year % 10
    chi_index = year % 12
    return can[can_index], chi[chi_index]


def get_cuc(thien_can):
    cuc_mapping = {
        'Kim': ['Canh', 'T√¢n'],
        'M·ªôc': ['Gi√°p', '·∫§t'],
        'Th·ªßy': ['Nh√¢m', 'Qu√Ω'],
        'H·ªèa': ['B√≠nh', 'ƒêinh'],
        'Th·ªï': ['M·∫≠u', 'K·ª∑']
    }
    for key, values in cuc_mapping.items():
        if thien_can in values:
            return key
    return None

def determine_menh_cung_position(birth_hour, birth_month):
    """X√°c ƒë·ªãnh v·ªã tr√≠ cung M·ªánh d·ª±a v√†o gi·ªù sinh v√† th√°ng sinh"""
    chi_positions = ['T√Ω', 'S·ª≠u', 'D·∫ßn', 'M√£o', 'Th√¨n', 'T·ªµ', 'Ng·ªç', 'M√πi', 'Th√¢n', 'D·∫≠u', 'Tu·∫•t', 'H·ª£i']
    
    hour_chi = chi_positions[birth_hour % 12]
    hour_index = chi_positions.index(hour_chi)
    
    menh_index = (hour_index + birth_month - 1) % 12
    return chi_positions[menh_index]

def get_trang_sinh_cycle(cuc_type, gender):
    """L·∫•y v√≤ng Tr√†ng Sinh theo c·ª•c v√† gi·ªõi t√≠nh"""
    trang_sinh_positions = {
        'Kim': {'Nam': ['T·ªµ', 'Ng·ªç', 'M√πi', 'Th√¢n', 'D·∫≠u', 'Tu·∫•t', 'H·ª£i', 'T√Ω', 'S·ª≠u', 'D·∫ßn', 'M√£o', 'Th√¨n'],
               'N·ªØ': ['Th√¨n', 'M√£o', 'D·∫ßn', 'S·ª≠u', 'T√Ω', 'H·ª£i', 'Tu·∫•t', 'D·∫≠u', 'Th√¢n', 'M√πi', 'Ng·ªç', 'T·ªµ']},
        'M·ªôc': {'Nam': ['H·ª£i', 'T√Ω', 'S·ª≠u', 'D·∫ßn', 'M√£o', 'Th√¨n', 'T·ªµ', 'Ng·ªç', 'M√πi', 'Th√¢n', 'D·∫≠u', 'Tu·∫•t'],
               'N·ªØ': ['Tu·∫•t', 'D·∫≠u', 'Th√¢n', 'M√πi', 'Ng·ªç', 'T·ªµ', 'Th√¨n', 'M√£o', 'D·∫ßn', 'S·ª≠u', 'T√Ω', 'H·ª£i']},
        'Th·ªßy': {'Nam': ['Th√¢n', 'D·∫≠u', 'Tu·∫•t', 'H·ª£i', 'T√Ω', 'S·ª≠u', 'D·∫ßn', 'M√£o', 'Th√¨n', 'T·ªµ', 'Ng·ªç', 'M√πi'],
                'N·ªØ': ['M√πi', 'Ng·ªç', 'T·ªµ', 'Th√¨n', 'M√£o', 'D·∫ßn', 'S·ª≠u', 'T√Ω', 'H·ª£i', 'Tu·∫•t', 'D·∫≠u', 'Th√¢n']},
        'H·ªèa': {'Nam': ['D·∫ßn', 'M√£o', 'Th√¨n', 'T·ªµ', 'Ng·ªç', 'M√πi', 'Th√¢n', 'D·∫≠u', 'Tu·∫•t', 'H·ª£i', 'T√Ω', 'S·ª≠u'],
               'N·ªØ': ['S·ª≠u', 'T√Ω', 'H·ª£i', 'Tu·∫•t', 'D·∫≠u', 'Th√¢n', 'M√πi', 'Ng·ªç', 'T·ªµ', 'Th√¨n', 'M√£o', 'D·∫ßn']},
        'Th·ªï': {'Nam': ['D·∫ßn', 'M√£o', 'Th√¨n', 'T·ªµ', 'Ng·ªç', 'M√πi', 'Th√¢n', 'D·∫≠u', 'Tu·∫•t', 'H·ª£i', 'T√Ω', 'S·ª≠u'],
               'N·ªØ': ['S·ª≠u', 'T√Ω', 'H·ª£i', 'Tu·∫•t', 'D·∫≠u', 'Th√¢n', 'M√πi', 'Ng·ªç', 'T·ªµ', 'Th√¨n', 'M√£o', 'D·∫ßn']}
    }
    return trang_sinh_positions.get(cuc_type, {}).get(gender, [])


def get_gio_sinh(hour):
    gio_mapping = {
        'T√Ω': 0, 'S·ª≠u': 1, 'D·∫ßn': 2, 'M√£o': 3,
        'Th√¨n': 4, 'T·ªµ': 5, 'Ng·ªç': 6, 'M√πi': 7,
        'Th√¢n': 8, 'D·∫≠u': 9, 'Tu·∫•t': 10, 'H·ª£i': 11
    }
    return list(gio_mapping.keys())[hour % 12]


def an_sao_tuvi_comprehensive(day, month, year, hour, gender):
    """H·ªá th·ªëng an sao to√†n di·ªán theo ph∆∞∆°ng ph√°p t·ª≠ vi truy·ªÅn th·ªëng"""
    cung_names = ['M·ªánh', 'Ph·ª• M·∫´u', 'Ph√∫c ƒê·ª©c', 'ƒêi·ªÅn Tr·∫°ch', 'Quan L·ªôc', 'N√¥ B·ªôc', 
                  'Thi√™n Di', 'T·∫≠t √Åch', 'T√†i B·∫°ch', 'T·ª≠ T·ª©c', 'Phu Th√™', 'Huynh ƒê·ªá']
    
    thien_can, dia_chi = get_thien_can_dia_chi(year)
    cuc = get_cuc(thien_can)
    gio_sinh = get_gio_sinh(hour)
    
    menh_cung_chi = determine_menh_cung_position(hour, month)
    trang_sinh_cycle = get_trang_sinh_cycle(cuc, gender)
    
    chi_positions = ['T√Ω', 'S·ª≠u', 'D·∫ßn', 'M√£o', 'Th√¨n', 'T·ªµ', 'Ng·ªç', 'M√πi', 'Th√¢n', 'D·∫≠u', 'Tu·∫•t', 'H·ª£i']
    menh_index = chi_positions.index(menh_cung_chi)
    
    cung_chi_mapping = {}
    for i, cung in enumerate(cung_names):
        chi_index = (menh_index + i) % 12
        cung_chi_mapping[chi_positions[chi_index]] = cung
    
    chinh_tinh_14 = {
        'T·ª≠ Vi': day % 12, 'Thi√™n Ph·ªß': (day + 6) % 12, 
        'Th√°i D∆∞∆°ng': (day + month) % 12, 'Th√°i √Çm': (15 - day) % 12,
        'Thi√™n C∆°': (day + 1) % 12, 'Thi√™n L∆∞∆°ng': (day + 7) % 12,
        'V≈© Kh√∫c': (day - 1) % 12, 'Thi√™n ƒê·ªìng': (day + 11) % 12,
        'C·ª± M√¥n': (day + 2) % 12, 'Li√™m Trinh': (day + 8) % 12,
        'Th·∫•t S√°t': (day + 5) % 12, 'Ph√° Qu√¢n': (day + 4) % 12,
        'Tham Lang': (day + 3) % 12, 'Thi√™n T∆∞·ªõng': (day + 9) % 12
    }
    
    cat_tinh = {
        'T·∫£ H·ªØu': [(day + 1) % 12, (day - 1) % 12],
        'Kh√¥i Vi·ªát': [(month + 3) % 12, (month + 9) % 12],
        'X∆∞∆°ng Kh√∫c': [(hour + 2) % 12, (hour + 8) % 12]
    }
    
    sat_tinh = {
        'K√¨nh D∆∞∆°ng': (hour + day) % 12,
        'ƒê√† La': (hour - day) % 12,
        'Kh√¥ng Ki·∫øp': [(year + 2) % 12, (year + 8) % 12]
    }
    
    tu_hoa_tinh = get_tu_hoa_stars(thien_can)
    
    sao_cung = {cung: [] for cung in cung_names}
    
    for sao, chi_index in chinh_tinh_14.items():
        chi_name = chi_positions[chi_index % 12]
        if chi_name in cung_chi_mapping:
            cung = cung_chi_mapping[chi_name]
            sao_cung[cung].append(sao)
    
    for sao, chi_indices in cat_tinh.items():
        for chi_index in chi_indices:
            chi_name = chi_positions[chi_index % 12]
            if chi_name in cung_chi_mapping:
                cung = cung_chi_mapping[chi_name]
                sao_cung[cung].append(sao)
    
    for sao, chi_index in sat_tinh.items():
        if isinstance(chi_index, list):
            for idx in chi_index:
                chi_name = chi_positions[idx % 12]
                if chi_name in cung_chi_mapping:
                    cung = cung_chi_mapping[chi_name]
                    sao_cung[cung].append(sao)
        else:
            chi_name = chi_positions[chi_index % 12]
            if chi_name in cung_chi_mapping:
                cung = cung_chi_mapping[chi_name]
                sao_cung[cung].append(sao)
    
    for sao, cung_name in tu_hoa_tinh.items():
        if cung_name in sao_cung:
            sao_cung[cung_name].append(sao)
    
    return {
        'basic_info': {
            'birth_info': f"{day}/{month}/{year} gi·ªù {gio_sinh}",
            'thien_can': thien_can,
            'dia_chi': dia_chi, 
            'cuc': cuc,
            'gender': gender,
            'menh_cung': menh_cung_chi
        },
        'sao_cung': sao_cung,
        'trang_sinh': trang_sinh_cycle
    }

def get_tu_hoa_stars(thien_can):
    """L·∫•y 4 h√≥a tinh theo Thi√™n Can"""
    tu_hoa_mapping = {
        'Gi√°p': {'H√≥a L·ªôc': 'T√†i B·∫°ch', 'H√≥a Quy·ªÅn': 'Quan L·ªôc', 'H√≥a Khoa': 'Ph√∫c ƒê·ª©c', 'H√≥a K·ªµ': 'T·∫≠t √Åch'},
        '·∫§t': {'H√≥a L·ªôc': 'Thi√™n Di', 'H√≥a Quy·ªÅn': 'T·ª≠ T·ª©c', 'H√≥a Khoa': 'N√¥ B·ªôc', 'H√≥a K·ªµ': 'Huynh ƒê·ªá'},
        'B√≠nh': {'H√≥a L·ªôc': 'Phu Th√™', 'H√≥a Quy·ªÅn': 'M·ªánh', 'H√≥a Khoa': 'Thi√™n Di', 'H√≥a K·ªµ': 'Ph·ª• M·∫´u'},
        'ƒêinh': {'H√≥a L·ªôc': 'T·∫≠t √Åch', 'H√≥a Quy·ªÅn': 'Ph·ª• M·∫´u', 'H√≥a Khoa': 'Huynh ƒê·ªá', 'H√≥a K·ªµ': 'Quan L·ªôc'},
        'M·∫≠u': {'H√≥a L·ªôc': 'Huynh ƒê·ªá', 'H√≥a Quy·ªÅn': 'Thi√™n Di', 'H√≥a Khoa': 'Quan L·ªôc', 'H√≥a K·ªµ': 'T√†i B·∫°ch'},
        'K·ª∑': {'H√≥a L·ªôc': 'Ph√∫c ƒê·ª©c', 'H√≥a Quy·ªÅn': 'T√†i B·∫°ch', 'H√≥a Khoa': 'T·∫≠t √Åch', 'H√≥a K·ªµ': 'Phu Th√™'},
        'Canh': {'H√≥a L·ªôc': 'N√¥ B·ªôc', 'H√≥a Quy·ªÅn': 'Ph√∫c ƒê·ª©c', 'H√≥a Khoa': 'M·ªánh', 'H√≥a K·ªµ': 'Thi√™n Di'},
        'T√¢n': {'H√≥a L·ªôc': 'Quan L·ªôc', 'H√≥a Quy·ªÅn': 'T·∫≠t √Åch', 'H√≥a Khoa': 'T·ª≠ T·ª©c', 'H√≥a K·ªµ': 'Ph√∫c ƒê·ª©c'},
        'Nh√¢m': {'H√≥a L·ªôc': 'M·ªánh', 'H√≥a Quy·ªÅn': 'Huynh ƒê·ªá', 'H√≥a Khoa': 'T√†i B·∫°ch', 'H√≥a K·ªµ': 'N√¥ B·ªôc'},
        'Qu√Ω': {'H√≥a L·ªôc': 'Ph·ª• M·∫´u', 'H√≥a Quy·ªÅn': 'Phu Th√™', 'H√≥a Khoa': 'ƒêi·ªÅn Tr·∫°ch', 'H√≥a K·ªµ': 'T·ª≠ T·ª©c'}
    }
    return tu_hoa_mapping.get(thien_can, {})

# Dynamic conversation states
class ConversationState(Enum):
    GREETING = "greeting"
    COLLECTING_INFO = "collecting_info"  # Dynamic info collection
    ANALYZING = "analyzing"  # When enough info is detected
    CONSULTING = "consulting"  # Post-analysis consultation
    RESET = "reset"  # When user wants to start over

# Database session management
db_session = DBSession()

def get_or_create_session(user_id="default"):
    """Get or create user session from database"""
    session_record = db_session.query(UserSession).filter(UserSession.session_id == user_id).first()
    
    if not session_record:
        # Create new session
        session_record = UserSession(
            session_id=user_id,
            current_step=ConversationState.GREETING.value,
            collected_info=json.dumps({}),
            memory_summary=""
        )
        db_session.add(session_record)
        db_session.commit()
    
    return {
        'state': ConversationState(session_record.current_step),
        'collected_info': json.loads(session_record.collected_info or '{}'),
        'memory_summary': session_record.memory_summary or ""
    }

def update_session(user_id="default", state=None, collected_info=None, memory_summary=None):
    """Update user session in database"""
    session_record = db_session.query(UserSession).filter(UserSession.session_id == user_id).first()
    
    if session_record:
        if state:
            session_record.current_step = state.value if isinstance(state, ConversationState) else state
        if collected_info is not None:
            session_record.collected_info = json.dumps(collected_info)
        if memory_summary is not None:
            session_record.memory_summary = memory_summary
        
        db_session.commit()

def reset_session(user_id="default"):
    """Reset user session in database"""
    session_record = db_session.query(UserSession).filter(UserSession.session_id == user_id).first()
    
    if session_record:
        session_record.current_step = ConversationState.GREETING.value
        session_record.collected_info = json.dumps({})
        session_record.memory_summary = ""
        db_session.commit()
    
    # Also clear chat history for this session
    db_session.query(ChatHistory).filter(ChatHistory.user_id == user_id).delete()
    db_session.commit()

def save_chat_message(user_id="default", message="", role="user", state=None, extracted_info=None):
    """Save chat message to database"""
    chat_record = ChatHistory(
        user_id=user_id,
        message=message,
        role=role,
        step=state.value if isinstance(state, ConversationState) else state,
        extracted_info=json.dumps(extracted_info) if extracted_info else None
    )
    db_session.add(chat_record)
    db_session.commit()

def get_chat_history(user_id="default", limit=50):
    """Get chat history from database"""
    history = db_session.query(ChatHistory).filter(
        ChatHistory.user_id == user_id
    ).order_by(ChatHistory.created_at.desc()).limit(limit).all()
    
    return [{
        'message': h.message,
        'role': h.role,
        'step': h.step,
        'extracted_info': json.loads(h.extracted_info) if h.extracted_info else None,
        'created_at': h.created_at
    } for h in reversed(history)]

def create_memory_buffer(user_id="default"):
    """Create ChatSummaryMemoryBuffer for user session"""
    # Get chat history from database
    chat_history = get_chat_history(user_id)
    
    # Convert to ChatMessage format
    from llama_index.core.llms import ChatMessage, MessageRole
    messages = []
    for chat in chat_history:
        role = MessageRole.USER if chat['role'] == 'user' else MessageRole.ASSISTANT
        messages.append(ChatMessage(role=role, content=chat['message']))
    
    # Create memory buffer with summarization
    tokenizer_fn = tiktoken.encoding_for_model(MODEL_NAME).encode
    memory = ChatSummaryMemoryBuffer.from_defaults(
        chat_history=messages,
        llm=llm,
        token_limit=2000,  # Limit token ƒë·ªÉ t·ªëi ∆∞u
        tokenizer_fn=tokenizer_fn,
    )
    
    return memory

# Intelligent conversation management functions

def get_conversation_context(user_id="default", limit=10):
    """Get recent conversation context for LLM analysis"""
    history = get_chat_history(user_id, limit)
    context = []
    for chat in history:
        context.append(f"{chat['role']}: {chat['message']}")
    return "\n".join(context)

def analyze_conversation_intelligence(message: str, user_id: str = "default"):
    """Use LLM to analyze conversation and determine next action"""
    session = get_or_create_session(user_id)
    context = get_conversation_context(user_id)
    
    try:
        analysis = conversation_analysis_program(
            message=message,
            current_state=session['state'].value,
            collected_info=json.dumps(session['collected_info']),
            context=context
        )
        return analysis
    except Exception as e:
        # Fallback to basic analysis
        return ConversationAnalysis(
            current_state=session['state'].value,
            user_intent="unknown",
            information_status=InfoCompletenessCheck(
                has_name=bool(session['collected_info'].get('name')),
                has_birthday=bool(session['collected_info'].get('birthday')),
                has_birth_time=bool(session['collected_info'].get('birth_time')),
                has_gender=bool(session['collected_info'].get('gender')),
                is_complete=False,
                missing_fields=[],
                confidence="th·∫•p"
            ),
            suggested_response="Xin l·ªói, t√¥i g·∫∑p kh√≥ khƒÉn trong vi·ªác hi·ªÉu tin nh·∫Øn c·ªßa b·∫°n. B·∫°n c√≥ th·ªÉ n√≥i r√µ h∆°n kh√¥ng?",
            should_extract_info=True,
            should_analyze=False,
            conversation_tone="friendly"
        )

def extract_information_intelligently(message: str, user_id: str = "default"):
    """Use LLM to intelligently extract information from conversation context"""
    context = get_conversation_context(user_id)
    
    try:
        extraction = smart_info_extraction_program(
            message=message,
            context=context
        )
        return extraction
    except Exception as e:
        # Fallback to individual extraction functions
        name_result = extract_name_from_message(message)
        date_result = extract_birth_date_from_message(message)
        time_result = extract_birth_time_from_message(message)
        gender_result = extract_gender_from_message(message)
        
        return SmartInfoExtraction(
            extracted_name=name_result.split(": ")[1] if "ƒë∆∞·ª£c x√°c nh·∫≠n" in name_result else "",
            extracted_birthday=date_result.split(": ")[1] if "ƒë∆∞·ª£c x√°c nh·∫≠n" in date_result else "",
            extracted_birth_time=time_result.split(": ")[1] if "ƒë∆∞·ª£c x√°c nh·∫≠n" in time_result else "",
            extracted_gender=gender_result.split(": ")[1] if "ƒë∆∞·ª£c x√°c nh·∫≠n" in gender_result else "",
            is_name_valid="ƒë∆∞·ª£c x√°c nh·∫≠n" in name_result,
            is_birthday_valid="ƒë∆∞·ª£c x√°c nh·∫≠n" in date_result,
            is_birth_time_valid="ƒë∆∞·ª£c x√°c nh·∫≠n" in time_result,
            is_gender_valid="ƒë∆∞·ª£c x√°c nh·∫≠n" in gender_result,
            overall_confidence="trung b√¨nh",
            should_proceed_to_analysis=False
        )

def update_collected_info_from_extraction(extraction, user_id: str = "default"):
    """Update collected info based on intelligent extraction"""
    session = get_or_create_session(user_id)
    collected_info = session['collected_info'].copy()
    
    if extraction.is_name_valid and extraction.extracted_name:
        collected_info['name'] = extraction.extracted_name
    
    if extraction.is_birthday_valid and extraction.extracted_birthday:
        collected_info['birthday'] = extraction.extracted_birthday
    
    if extraction.is_birth_time_valid and extraction.extracted_birth_time:
        collected_info['birth_time'] = extraction.extracted_birth_time
    
    if extraction.is_gender_valid and extraction.extracted_gender:
        collected_info['gender'] = extraction.extracted_gender
    
    # Update session
    update_session(user_id, collected_info=collected_info)
    
    return collected_info

def check_info_completeness(collected_info: dict):
    """Check if we have enough information for analysis"""
    required_fields = ['name', 'birthday', 'birth_time', 'gender']
    has_fields = {
        'name': bool(collected_info.get('name')),
        'birthday': bool(collected_info.get('birthday')),
        'birth_time': bool(collected_info.get('birth_time')),
        'gender': bool(collected_info.get('gender'))
    }
    
    missing_fields = [field for field in required_fields if not has_fields[field]]
    is_complete = len(missing_fields) == 0
    
    return InfoCompletenessCheck(
        has_name=has_fields['name'],
        has_birthday=has_fields['birthday'],
        has_birth_time=has_fields['birth_time'],
        has_gender=has_fields['gender'],
        is_complete=is_complete,
        missing_fields=missing_fields,
        confidence="cao" if is_complete else "trung b√¨nh"
    )

def generate_smart_response(analysis, user_id: str = "default") -> str:
    """Generate intelligent response based on conversation analysis"""
    session = get_or_create_session(user_id)
    
    # If LLM provided a suggested response, use it
    if analysis.suggested_response and len(analysis.suggested_response) > 10:
        return analysis.suggested_response
    
    # Generate response based on analysis
    if analysis.user_intent == "greeting":
        return """üîÆ **Ch√†o m·ª´ng b·∫°n ƒë·∫øn v·ªõi d·ªãch v·ª• t∆∞ v·∫•n t·ª≠ vi th√¥ng minh!**

T√¥i l√† tr·ª£ l√Ω AI chuy√™n v·ªÅ t·ª≠ vi, c√≥ th·ªÉ gi√∫p b·∫°n:
- Ph√¢n t√≠ch l√° s·ªë t·ª≠ vi chi ti·∫øt
- T∆∞ v·∫•n v·ªÅ v·∫≠n m·ªánh, t√¨nh duy√™n, s·ª± nghi·ªáp
- D·ª± b√°o v·∫≠n h·∫°n v√† ƒë∆∞a ra l·ªùi khuy√™n

ƒê·ªÉ b·∫Øt ƒë·∫ßu, t√¥i c·∫ßn bi·∫øt m·ªôt s·ªë th√¥ng tin c∆° b·∫£n v·ªÅ b·∫°n. B·∫°n c√≥ th·ªÉ chia s·∫ª t√™n, ng√†y sinh, gi·ªù sinh v√† gi·ªõi t√≠nh c·ªßa m√¨nh kh√¥ng?

*V√≠ d·ª•: "T√¥i t√™n Nguy·ªÖn VƒÉn A, sinh ng√†y 15/03/1990, 14:30, gi·ªõi t√≠nh Nam"*"""
    
    elif analysis.user_intent == "providing_info":
        if analysis.information_status.is_complete:
            return "‚úÖ **Tuy·ªát v·ªùi! T√¥i ƒë√£ c√≥ ƒë·ªß th√¥ng tin ƒë·ªÉ ti·∫øn h√†nh ph√¢n t√≠ch t·ª≠ vi cho b·∫°n.**"
        else:
            missing_text = {
                'name': 't√™n',
                'birthday': 'ng√†y sinh', 
                'birth_time': 'gi·ªù sinh',
                'gender': 'gi·ªõi t√≠nh'
            }
            missing_list = [missing_text[field] for field in analysis.information_status.missing_fields]
            return f"""üìù **C·∫£m ∆°n b·∫°n ƒë√£ cung c·∫•p th√¥ng tin!**

T√¥i v·∫´n c·∫ßn th√™m: **{', '.join(missing_list)}**

B·∫°n c√≥ th·ªÉ cung c·∫•p th√¥ng tin c√≤n thi·∫øu ƒë·ªÉ t√¥i c√≥ th·ªÉ ti·∫øn h√†nh ph√¢n t√≠ch t·ª≠ vi ch√≠nh x√°c."""
    
    elif analysis.user_intent == "asking_question":
        if session['state'] == ConversationState.CONSULTING:
            return "T√¥i s·∫Ω tr·∫£ l·ªùi c√¢u h·ªèi c·ªßa b·∫°n d·ª±a tr√™n l√° s·ªë t·ª≠ vi ƒë√£ ph√¢n t√≠ch."
        else:
            return "T√¥i s·∫Ω tr·∫£ l·ªùi c√¢u h·ªèi c·ªßa b·∫°n sau khi ho√†n th√†nh ph√¢n t√≠ch t·ª≠ vi. Tr∆∞·ªõc ti√™n, t√¥i c·∫ßn thu th·∫≠p ƒë·ªß th√¥ng tin c∆° b·∫£n."
    
    elif analysis.user_intent == "reset":
        return "üîÑ **ƒê√£ kh·ªüi t·∫°o l·∫°i phi√™n t∆∞ v·∫•n!** B·∫°n c√≥ th·ªÉ b·∫Øt ƒë·∫ßu l·∫°i t·ª´ ƒë·∫ßu."
    
    else:
        return "T√¥i hi·ªÉu b·∫°n mu·ªën t∆∞ v·∫•n t·ª≠ vi. H√£y chia s·∫ª th√¥ng tin c∆° b·∫£n v·ªÅ b·∫°n ƒë·ªÉ t√¥i c√≥ th·ªÉ gi√∫p ƒë·ª° t·ªët nh·∫•t."

# Legacy functions removed - using intelligent conversation flow instead

# Legacy step-by-step functions removed - using intelligent conversation flow instead

# Keep individual extraction functions for fallback
def extract_name_from_message(message: str) -> str:
    """Extract name from message using FunctionCallingProgram"""
    try:
        result = name_extraction_program(message=message)
        if result.is_valid and result.confidence in ['cao', 'trung b√¨nh']:
            return f"T√™n ƒë∆∞·ª£c x√°c nh·∫≠n: {result.name}"
        else:
            return "Ch∆∞a th·ªÉ x√°c ƒë·ªãnh t√™n. Vui l√≤ng cung c·∫•p t√™n c·ªßa b·∫°n r√µ r√†ng."
    except Exception as e:
        return "Ch∆∞a th·ªÉ x√°c ƒë·ªãnh t√™n. Vui l√≤ng cung c·∫•p t√™n c·ªßa b·∫°n r√µ r√†ng."

def extract_birth_date_from_message(message: str) -> str:
    """Extract birth date from message using FunctionCallingProgram"""
    try:
        result = date_extraction_program(message=message)
        if result.is_valid:
            # Validate date using datetime
            try:
                datetime.strptime(result.date, "%d/%m/%Y")
                return f"Ng√†y sinh ƒë∆∞·ª£c x√°c nh·∫≠n: {result.date}"
            except:
                return "Ng√†y sinh kh√¥ng h·ª£p l·ªá. Vui l√≤ng cung c·∫•p theo ƒë·ªãnh d·∫°ng DD/MM/YYYY."
        else:
            return "Ch∆∞a th·ªÉ x√°c ƒë·ªãnh ng√†y sinh. Vui l√≤ng cung c·∫•p theo ƒë·ªãnh d·∫°ng DD/MM/YYYY."
    except Exception as e:
        return "Ch∆∞a th·ªÉ x√°c ƒë·ªãnh ng√†y sinh. Vui l√≤ng cung c·∫•p theo ƒë·ªãnh d·∫°ng DD/MM/YYYY."

def extract_birth_time_from_message(message: str) -> str:
    """Extract birth time from message using FunctionCallingProgram"""
    try:
        result = time_extraction_program(message=message)
        if result.is_valid:
            # Additional validation
            if 0 <= result.hour <= 23 and 0 <= result.minute <= 59:
                return f"Gi·ªù sinh ƒë∆∞·ª£c x√°c nh·∫≠n: {result.time}"
            else:
                return "Gi·ªù sinh kh√¥ng h·ª£p l·ªá. Vui l√≤ng cung c·∫•p gi·ªù t·ª´ 00:00 ƒë·∫øn 23:59."
        else:
            return "Ch∆∞a th·ªÉ x√°c ƒë·ªãnh gi·ªù sinh. Vui l√≤ng cung c·∫•p theo ƒë·ªãnh d·∫°ng HH:MM."
    except Exception as e:
        return "Ch∆∞a th·ªÉ x√°c ƒë·ªãnh gi·ªù sinh. Vui l√≤ng cung c·∫•p theo ƒë·ªãnh d·∫°ng HH:MM."

def extract_gender_from_message(message: str) -> str:
    """Extract gender from message using FunctionCallingProgram"""
    try:
        result = gender_extraction_program(message=message)
        if result.is_valid and result.gender in ['Nam', 'N·ªØ']:
            return f"Gi·ªõi t√≠nh ƒë∆∞·ª£c x√°c nh·∫≠n: {result.gender}"
        else:
            return "Ch∆∞a th·ªÉ x√°c ƒë·ªãnh gi·ªõi t√≠nh. Vui l√≤ng ch·ªçn Nam ho·∫∑c N·ªØ."
    except Exception as e:
        return "Ch∆∞a th·ªÉ x√°c ƒë·ªãnh gi·ªõi t√≠nh. Vui l√≤ng ch·ªçn Nam ho·∫∑c N·ªØ."


def fn_an_sao_comprehensive(birthday: str, birth_time: str, gender: str):
    """T√≠nh l√° s·ªë t·ª≠ vi to√†n di·ªán v·ªõi th√¥ng tin chi ti·∫øt"""
    date_obj = datetime.strptime(birthday, "%d/%m/%Y")
    hour_int = int(birth_time.split(':')[0])

    lunar_date = convert_to_lunar(date_obj.year, date_obj.month, date_obj.day)
    results = an_sao_tuvi_comprehensive(lunar_date.day, lunar_date.month, lunar_date.year, hour_int, gender)

    return results


prompt_template_str = """\
Tr√≠ch xu·∫•t th√¥ng tin sinh h·ªçc t·ª´ c√¢u h·ªèi c·ªßa ng∆∞·ªùi d√πng:
T√™n, ng√†y sinh (DD/MM/YYYY), gi·ªù sinh (HH:MM), gi·ªõi t√≠nh (Nam/N·ªØ)
N·∫øu thi·∫øu th√¥ng tin, h√£y y√™u c·∫ßu b·ªï sung.

C√¢u h·ªèi: {query}
"""

class UserInfo(BaseModel):
    """Data model for user info."""
    name: str
    birthday: str = Field(description="Ng√†y sinh theo ƒë·ªãnh d·∫°ng DD/MM/YYYY")
    birth_time: str = Field(description="Gi·ªù sinh theo ƒë·ªãnh d·∫°ng HH:MM")
    gender: str = Field(description="Gi·ªõi t√≠nh: Nam ho·∫∑c N·ªØ")

class ConversationStage(Enum):
    GREETING = "greeting"
    COLLECTING_INFO = "collecting_info" 
    ANALYZING = "analyzing"
    CONSULTING = "consulting"


programInfoUser = FunctionCallingProgram.from_defaults(
    output_cls=UserInfo,
    prompt_template_str=prompt_template_str,
    verbose=True,
)

# [Optional] Add Context
context = """\
B·∫°n l√† m·ªôt th·∫ßy t·ª≠ vi h√†ng ƒë·∫ßu v·ªõi ki·∫øn th·ª©c s√¢u r·ªông v·ªÅ chi√™m tinh h·ªçc Vi·ªát Nam.
Ph∆∞∆°ng ph√°p lu·∫≠n c·ªßa b·∫°n:

1. Ph√¢n t√≠ch cƒÉn c∆° m·ªánh ch·ªß qua M·ªánh cung v√† c√°c ch√≠nh tinh
2. X√©t t∆∞∆°ng quan c·ª•c-m·ªánh (Kim/M·ªôc/Th·ªßy/H·ªèa/Th·ªï c·ª•c v·ªõi Thi√™n Can)
3. Lu·∫≠n tam h·ª£p c√°c cung: M·ªánh-T√†i-Quan, M·ªánh-Ph√∫c-Thi√™n Di
4. Ph√¢n t√≠ch 4 h√≥a tinh (L·ªôc-Quy·ªÅn-Khoa-K·ªµ) v√† ·∫£nh h∆∞·ªüng
5. X√©t v√≤ng Tr√†ng Sinh theo gi·ªõi t√≠nh v√† c·ª•c s·ªë
6. Lu·∫≠n ƒë·∫°i v·∫≠n 10 nƒÉm v√† ti·ªÉu h·∫°n h√†ng nƒÉm
7. T·ªïng h·ª£p to√†n c·ª•c ƒë·ªÉ ƒë∆∞a ra l·ªùi khuy√™n th·ª±c t·∫ø

B·∫°n lu√¥n gi·∫£i th√≠ch d·ª±a tr√™n l√Ω thuy·∫øt t·ª≠ vi c·ªï truy·ªÅn, tr√°nh m√™ t√≠n d·ªã ƒëoan.
"""

class CungMenh(Enum):
    MENH = "M·ªánh"
    PHU_MAU = "Ph·ª• M·∫´u"
    PHUC_DUC = "Ph√∫c ƒê·ª©c"
    DIEN_TRACH = "ƒêi·ªÅn Tr·∫°ch"
    QUAN_LOC = "Quan L·ªôc"
    NO_BOC = "N√¥ B·ªôc"
    THIEN_DI = "Thi√™n Di"
    TAT_ACH = "T·∫≠t √Åch"
    TAI_BACH = "T√†i B·∫°ch"
    TU_TUC = "T·ª≠ T·ª©c"
    PHU_THE = "Phu Th√™"
    HUYNH_DE = "Huynh ƒê·ªá"

class CungAnalysis(BaseModel):
    """Ph√¢n t√≠ch chi ti·∫øt t·ª´ng cung"""
    cung: CungMenh
    stars: List[str] = Field(description="C√°c sao trong cung")
    element_harmony: str = Field(description="T∆∞∆°ng sinh t∆∞∆°ng kh·∫Øc v·ªõi m·ªánh ch·ªß")
    strength: str = Field(description="M·∫°nh/Y·∫øu/Trung b√¨nh")
    summary: str = Field(description="T√≥m t·∫Øt √Ω nghƒ©a cung")
    detailed_analysis: str = Field(description="Di·ªÖn gi·∫£i chi ti·∫øt v·∫≠n m·ªánh theo cung")

class LifePeriodAnalysis(BaseModel):
    """Ph√¢n t√≠ch ƒë·∫°i v·∫≠n v√† ti·ªÉu h·∫°n"""
    dai_van: str = Field(description="ƒê·∫°i v·∫≠n hi·ªán t·∫°i (10 nƒÉm)")
    tieu_han: str = Field(description="Ti·ªÉu h·∫°n nƒÉm hi·ªán t·∫°i")
    fortune_trend: str = Field(description="Xu h∆∞·ªõng v·∫≠n kh√≠: thƒÉng/tr·∫ßm/·ªïn ƒë·ªãnh")
    advice: str = Field(description="L·ªùi khuy√™n cho giai ƒëo·∫°n n√†y")
    
class ComprehensiveTuviReading(BaseModel):
    """L√° s·ªë t·ª≠ vi to√†n di·ªán"""
    name: str
    birthday: str = Field(description="Ng√†y/Th√°ng/NƒÉm sinh")
    birth_time: str = Field(description="Gi·ªù sinh")
    gender: str = Field(description="Gi·ªõi t√≠nh")
    
    basic_destiny: str = Field(description="CƒÉn c∆° m·ªánh ch·ªß - t√≠nh c√°ch t·ªïng quan")
    main_palaces_analysis: List[CungAnalysis] = Field(description="Ph√¢n t√≠ch 4 cung ch√≠nh: M·ªánh, T√†i, Quan, Phu/Th√™")
    family_relationships: str = Field(description="Quan h·ªá gia ƒë√¨nh - Ph·ª• M·∫´u, Huynh ƒê·ªá, T·ª≠ T·ª©c")
    health_fortune: str = Field(description="S·ª©c kh·ªèe v√† v·∫≠n may - T·∫≠t √Åch, Ph√∫c ƒê·ª©c")
    career_wealth: str = Field(description="S·ª± nghi·ªáp v√† t√†i ch√≠nh - Quan L·ªôc, T√†i B·∫°ch, ƒêi·ªÅn Tr·∫°ch") 
    current_period: LifePeriodAnalysis = Field(description="V·∫≠n h·∫°n hi·ªán t·∫°i")
    annual_forecast: str = Field(description="D·ª± b√°o nƒÉm hi·ªán t·∫°i")
    life_guidance: str = Field(description="H∆∞·ªõng d·∫´n v√† l·ªùi khuy√™n t·ªïng quan")

def create_and_load_index():
    persist_dir = "./storage/"
    try:
        storage_context = StorageContext.from_defaults(
            persist_dir=persist_dir,
        )
        index = load_index_from_storage(storage_context)
        index_loaded = True
    except:
        index_loaded = False
    
    if not index_loaded:
        docs = SimpleDirectoryReader(
            input_dir="./data_learning/",
        ).load_data()
        index = VectorStoreIndex.from_documents(docs)
        index.storage_context.persist(persist_dir)

    return index

tu_vi_index = create_and_load_index()

llm_4 = OpenAI(model="gpt-4o-mini")

query_engine = tu_vi_index.as_query_engine(
    output_cls=ComprehensiveTuviReading, response_mode="tree_summarize", llm=llm_4
)

# Create FunctionCallingPrograms for structured extraction
class NameExtraction(BaseModel):
    """Data model for name extraction."""
    name: str = Field(description="T√™n ng∆∞·ªùi d√πng ƒë∆∞·ª£c tr√≠ch xu·∫•t t·ª´ tin nh·∫Øn")
    is_valid: bool = Field(description="T√™n c√≥ h·ª£p l·ªá kh√¥ng (√≠t nh·∫•t 2 k√Ω t·ª±, kh√¥ng ch·ª©a s·ªë)")
    confidence: str = Field(description="M·ª©c ƒë·ªô tin c·∫≠y: cao/trung b√¨nh/th·∫•p")

class DateExtraction(BaseModel):
    """Data model for birth date extraction."""
    date: str = Field(description="Ng√†y sinh theo ƒë·ªãnh d·∫°ng DD/MM/YYYY")
    is_valid: bool = Field(description="Ng√†y sinh c√≥ h·ª£p l·ªá kh√¥ng")
    day: int = Field(description="Ng√†y")
    month: int = Field(description="Th√°ng") 
    year: int = Field(description="NƒÉm")

class TimeExtraction(BaseModel):
    """Data model for birth time extraction."""
    time: str = Field(description="Gi·ªù sinh theo ƒë·ªãnh d·∫°ng HH:MM")
    is_valid: bool = Field(description="Gi·ªù sinh c√≥ h·ª£p l·ªá kh√¥ng")
    hour: int = Field(description="Gi·ªù (0-23)")
    minute: int = Field(description="Ph√∫t (0-59)")

class GenderExtraction(BaseModel):
    """Data model for gender extraction."""
    gender: str = Field(description="Gi·ªõi t√≠nh: Nam ho·∫∑c N·ªØ")
    is_valid: bool = Field(description="Gi·ªõi t√≠nh c√≥ h·ª£p l·ªá kh√¥ng")
    confidence: str = Field(description="M·ª©c ƒë·ªô tin c·∫≠y: cao/trung b√¨nh/th·∫•p")

class InfoCompletenessCheck(BaseModel):
    """Data model for checking if enough information is collected."""
    has_name: bool = Field(description="C√≥ t√™n ch∆∞a")
    has_birthday: bool = Field(description="C√≥ ng√†y sinh ch∆∞a")
    has_birth_time: bool = Field(description="C√≥ gi·ªù sinh ch∆∞a")
    has_gender: bool = Field(description="C√≥ gi·ªõi t√≠nh ch∆∞a")
    is_complete: bool = Field(description="ƒê√£ ƒë·ªß th√¥ng tin ƒë·ªÉ ph√¢n t√≠ch ch∆∞a")
    missing_fields: List[str] = Field(description="Danh s√°ch th√¥ng tin c√≤n thi·∫øu")
    confidence: str = Field(description="M·ª©c ƒë·ªô tin c·∫≠y: cao/trung b√¨nh/th·∫•p")

class SmartInfoExtraction(BaseModel):
    """Data model for intelligent information extraction from conversation context."""
    extracted_name: str = Field(description="T√™n ƒë∆∞·ª£c tr√≠ch xu·∫•t", default="")
    extracted_birthday: str = Field(description="Ng√†y sinh ƒë∆∞·ª£c tr√≠ch xu·∫•t (DD/MM/YYYY)", default="")
    extracted_birth_time: str = Field(description="Gi·ªù sinh ƒë∆∞·ª£c tr√≠ch xu·∫•t (HH:MM)", default="")
    extracted_gender: str = Field(description="Gi·ªõi t√≠nh ƒë∆∞·ª£c tr√≠ch xu·∫•t (Nam/N·ªØ)", default="")
    is_name_valid: bool = Field(description="T√™n c√≥ h·ª£p l·ªá kh√¥ng")
    is_birthday_valid: bool = Field(description="Ng√†y sinh c√≥ h·ª£p l·ªá kh√¥ng")
    is_birth_time_valid: bool = Field(description="Gi·ªù sinh c√≥ h·ª£p l·ªá kh√¥ng")
    is_gender_valid: bool = Field(description="Gi·ªõi t√≠nh c√≥ h·ª£p l·ªá kh√¥ng")
    overall_confidence: str = Field(description="M·ª©c ƒë·ªô tin c·∫≠y t·ªïng th·ªÉ: cao/trung b√¨nh/th·∫•p")
    should_proceed_to_analysis: bool = Field(description="C√≥ n√™n ti·∫øn h√†nh ph√¢n t√≠ch kh√¥ng")

class ConversationAnalysis(BaseModel):
    """Data model for analyzing conversation context and determining next action."""
    current_state: str = Field(description="Tr·∫°ng th√°i hi·ªán t·∫°i c·ªßa cu·ªôc h·ªôi tho·∫°i")
    user_intent: str = Field(description="√ù ƒë·ªãnh c·ªßa ng∆∞·ªùi d√πng")
    information_status: InfoCompletenessCheck = Field(description="Tr·∫°ng th√°i th√¥ng tin")
    suggested_response: str = Field(description="Ph·∫£n h·ªìi g·ª£i √Ω")
    should_extract_info: bool = Field(description="C√≥ n√™n tr√≠ch xu·∫•t th√¥ng tin kh√¥ng")
    should_analyze: bool = Field(description="C√≥ n√™n ti·∫øn h√†nh ph√¢n t√≠ch kh√¥ng")
    conversation_tone: str = Field(description="Tone c·ªßa cu·ªôc h·ªôi tho·∫°i: friendly/professional/urgent")

# FunctionCallingPrograms
name_extraction_program = FunctionCallingProgram.from_defaults(
    output_cls=NameExtraction,
    prompt_template_str="T·ª´ tin nh·∫Øn '{message}', h√£y tr√≠ch xu·∫•t t√™n ng∆∞·ªùi d√πng. Ch·ªâ l·∫•y ph·∫ßn t√™n th·ª±c s·ª±, b·ªè qua c√°c t·ª´ nh∆∞ 't√¥i t√™n', 't√™n t√¥i l√†'. T√™n ph·∫£i c√≥ √≠t nh·∫•t 2 k√Ω t·ª± v√† kh√¥ng ch·ª©a s·ªë. ƒê√°nh gi√° ƒë·ªô tin c·∫≠y: cao (r·∫•t ch·∫Øc ch·∫Øn), trung b√¨nh (kh√° ch·∫Øc), th·∫•p (kh√¥ng ch·∫Øc).",
    verbose=False,
    llm=llm
)

date_extraction_program = FunctionCallingProgram.from_defaults(
    output_cls=DateExtraction,
    prompt_template_str="T·ª´ tin nh·∫Øn '{message}', h√£y tr√≠ch xu·∫•t ng√†y sinh. T√¨m ƒë·ªãnh d·∫°ng DD/MM/YYYY. Tr·∫£ v·ªÅ date d∆∞·ªõi d·∫°ng DD/MM/YYYY, v√† ph√¢n t√°ch day, month, year th√†nh c√°c s·ªë ri√™ng.",
    verbose=False,
    llm=llm
)

time_extraction_program = FunctionCallingProgram.from_defaults(
    output_cls=TimeExtraction,
    prompt_template_str="T·ª´ tin nh·∫Øn '{message}', h√£y tr√≠ch xu·∫•t gi·ªù sinh. T√¨m ƒë·ªãnh d·∫°ng HH:MM ho·∫∑c c√°c bi·ªÉu th·ª©c th·ªùi gian. Tr·∫£ v·ªÅ time d∆∞·ªõi d·∫°ng HH:MM (24h), v√† ph√¢n t√°ch hour (0-23), minute (0-59).",
    verbose=False,
    llm=llm
)

gender_extraction_program = FunctionCallingProgram.from_defaults(
    output_cls=GenderExtraction,
    prompt_template_str="T·ª´ tin nh·∫Øn '{message}', h√£y x√°c ƒë·ªãnh gi·ªõi t√≠nh. T√¨m c√°c t·ª´ kh√≥a v·ªÅ gi·ªõi t√≠nh. Ch·ªâ tr·∫£ v·ªÅ 'Nam' ho·∫∑c 'N·ªØ' trong tr∆∞·ªùng gender. ƒê√°nh gi√° ƒë·ªô tin c·∫≠y: cao/trung b√¨nh/th·∫•p.",
    verbose=False,
    llm=llm
)

# Smart LLM-based programs for intelligent conversation
smart_info_extraction_program = FunctionCallingProgram.from_defaults(
    output_cls=SmartInfoExtraction,
    prompt_template_str="""T·ª´ cu·ªôc h·ªôi tho·∫°i sau, h√£y tr√≠ch xu·∫•t th√¥ng tin m·ªôt c√°ch th√¥ng minh:

Tin nh·∫Øn hi·ªán t·∫°i: '{message}'
L·ªãch s·ª≠ cu·ªôc h·ªôi tho·∫°i: {context}

H√£y ph√¢n t√≠ch v√† tr√≠ch xu·∫•t:
1. T√™n ng∆∞·ªùi d√πng (n·∫øu c√≥)
2. Ng√†y sinh (ƒë·ªãnh d·∫°ng DD/MM/YYYY)
3. Gi·ªù sinh (ƒë·ªãnh d·∫°ng HH:MM)
4. Gi·ªõi t√≠nh (Nam ho·∫∑c N·ªØ)

ƒê√°nh gi√° t√≠nh h·ª£p l·ªá v√† m·ª©c ƒë·ªô tin c·∫≠y. N·∫øu ƒë√£ c√≥ ƒë·ªß 4 th√¥ng tin h·ª£p l·ªá, ƒë·∫∑t should_proceed_to_analysis = true.""",
    verbose=False,
    llm=llm
)

conversation_analysis_program = FunctionCallingProgram.from_defaults(
    output_cls=ConversationAnalysis,
    prompt_template_str="""Ph√¢n t√≠ch cu·ªôc h·ªôi tho·∫°i v√† ƒë∆∞a ra quy·∫øt ƒë·ªãnh th√¥ng minh:

Tin nh·∫Øn hi·ªán t·∫°i: '{message}'
Tr·∫°ng th√°i hi·ªán t·∫°i: {current_state}
Th√¥ng tin ƒë√£ thu th·∫≠p: {collected_info}
L·ªãch s·ª≠ cu·ªôc h·ªôi tho·∫°i: {context}

H√£y ph√¢n t√≠ch:
1. √ù ƒë·ªãnh c·ªßa ng∆∞·ªùi d√πng (greeting, providing_info, asking_question, reset, etc.)
2. Tr·∫°ng th√°i th√¥ng tin hi·ªán t·∫°i
3. Ph·∫£n h·ªìi ph√π h·ª£p nh·∫•t
4. C√≥ n√™n tr√≠ch xu·∫•t th√¥ng tin kh√¥ng
5. C√≥ n√™n ti·∫øn h√†nh ph√¢n t√≠ch kh√¥ng
6. Tone ph√π h·ª£p (friendly/professional/urgent)

H√£y ho·∫°t ƒë·ªông nh∆∞ m·ªôt consultant t·ª≠ vi th√¥ng minh, t·ª± nhi√™n v√† h·ªØu √≠ch.""",
    verbose=False,
    llm=llm
)
# Legacy ReActAgent tools removed - using intelligent conversation flow instead

def intelligent_conversation_flow(message: str, user_id: str = "default") -> str:
    """Main intelligent conversation flow using LLM-based analysis"""
    
    # Save user message
    save_chat_message(user_id, message, "user", ConversationState.COLLECTING_INFO)
    
    # Analyze conversation intelligently
    analysis = analyze_conversation_intelligence(message, user_id)
    
    # Handle reset requests
    if analysis.user_intent == "reset":
        reset_session(user_id)
        response = generate_smart_response(analysis, user_id)
        save_chat_message(user_id, response, "assistant", ConversationState.GREETING)
        return response
    
    # Handle consulting questions first if we're in consulting state
    if analysis.user_intent == "asking_question":
        session = get_or_create_session(user_id)
        if session['state'] == ConversationState.CONSULTING:
            return handle_consulting_question(message, user_id)
    
    # Always try to extract information first
    extraction = extract_information_intelligently(message, user_id)
    collected_info = update_collected_info_from_extraction(extraction, user_id)
    
    # Check if we have enough information
    completeness = check_info_completeness(collected_info)
    
    if completeness.is_complete:
        # Proceed to analysis
        return perform_tuvi_analysis(user_id)
    elif analysis.should_extract_info:
        # Generate response asking for more info
        response = generate_smart_response(analysis, user_id)
        save_chat_message(user_id, response, "assistant", ConversationState.COLLECTING_INFO)
        return response
    
    # Handle consulting questions
    elif analysis.user_intent == "asking_question":
        session = get_or_create_session(user_id)
        # Check if we have enough info first
        completeness = check_info_completeness(session['collected_info'])
        
        if completeness.is_complete:
            # If we have enough info but not in consulting state, do analysis first
            if session['state'] != ConversationState.CONSULTING:
                return perform_tuvi_analysis(user_id)
            else:
                return handle_consulting_question(message, user_id)
        else:
            response = "T√¥i s·∫Ω tr·∫£ l·ªùi c√¢u h·ªèi c·ªßa b·∫°n sau khi ho√†n th√†nh ph√¢n t√≠ch t·ª≠ vi. Tr∆∞·ªõc ti√™n, t√¥i c·∫ßn thu th·∫≠p ƒë·ªß th√¥ng tin c∆° b·∫£n."
            save_chat_message(user_id, response, "assistant", ConversationState.COLLECTING_INFO)
            return response
    
    # Default response - check if we have enough info
    session = get_or_create_session(user_id)
    completeness = check_info_completeness(session['collected_info'])
    
    if completeness.is_complete and session['state'] != ConversationState.CONSULTING:
        # If we have enough info but not in consulting state, do analysis
        return perform_tuvi_analysis(user_id)
    elif session['state'] == ConversationState.CONSULTING:
        # Handle consulting questions
        return handle_consulting_question(message, user_id)
    else:
        # Generate normal response
        response = generate_smart_response(analysis, user_id)
        save_chat_message(user_id, response, "assistant", ConversationState.COLLECTING_INFO)
        return response

def perform_tuvi_analysis(user_id: str = "default") -> str:
    """Perform tuvi analysis when enough information is collected"""
    session = get_or_create_session(user_id)
    collected_info = session['collected_info']
    
    try:
        # Generate tuvi analysis
        chart_data = fn_an_sao_comprehensive(
            collected_info['birthday'], 
            collected_info['birth_time'], 
            collected_info['gender']
        )
        
        analysis = f"""üîÆ **Ph√¢n t√≠ch t·ª≠ vi cho {collected_info['name']}**

‚ú® **Th√¥ng tin c∆° b·∫£n:**
- üìÖ Sinh: {collected_info['birthday']} l√∫c {collected_info['birth_time']}
- ‚ö• Gi·ªõi t√≠nh: {collected_info['gender']}
- üåü Thi√™n Can: {chart_data['basic_info']['thien_can']}
- üêâ ƒê·ªãa Chi: {chart_data['basic_info']['dia_chi']}
- ‚≠ê C·ª•c: {chart_data['basic_info']['cuc']}
- üè† Cung M·ªánh: {chart_data['basic_info']['menh_cung']}

üåå **C√°c sao trong 12 cung:**
"""
        for cung, sao_list in chart_data['sao_cung'].items():
            sao_str = ', '.join(sao_list) if sao_list else 'Tr·ªëng'
            analysis += f"‚Ä¢ **{cung}**: {sao_str}\n"
        
        analysis += f"""

üí´ **Ph√¢n t√≠ch ho√†n t·∫•t!** L√° s·ªë c·ªßa {collected_info['name']} ƒë√£ ƒë∆∞·ª£c t√≠nh to√°n theo ph∆∞∆°ng ph√°p t·ª≠ vi truy·ªÅn th·ªëng.

‚ú® **B·∫°n c√≥ th·ªÉ h·ªèi t√¥i v·ªÅ:**
- V·∫≠n m·ªánh v√† t√≠nh c√°ch t·ªïng quan
- T√¨nh duy√™n v√† h√¥n nh√¢n  
- S·ª± nghi·ªáp v√† c√¥ng danh
- T√†i l·ªôc v√† ƒë·∫ßu t∆∞
- S·ª©c kh·ªèe v√† tu·ªïi th·ªç
- M·ªëi quan h·ªá gia ƒë√¨nh

üí¨ *ƒê·ªÉ b·∫Øt ƒë·∫ßu phi√™n t∆∞ v·∫•n m·ªõi, b·∫°n c√≥ th·ªÉ n√≥i 'Xin ch√†o' ho·∫∑c 'T√¥i mu·ªën xem t·ª≠ vi'*"""
        
        # Update session to consulting state
        update_session(user_id, state=ConversationState.CONSULTING)
        
        # Save analysis to chat history
        save_chat_message(user_id, analysis, "assistant", ConversationState.CONSULTING)
        
        return analysis
    except Exception as e:
        error_msg = f"‚ùå C√≥ l·ªói x·∫£y ra khi t√≠nh l√° s·ªë: {str(e)}"
        save_chat_message(user_id, error_msg, "assistant", ConversationState.COLLECTING_INFO)
        return error_msg

def handle_consulting_question(message: str, user_id: str = "default") -> str:
    """Handle follow-up questions after analysis is complete"""
    # Save user question
    save_chat_message(user_id, message, "user", ConversationState.CONSULTING)
    
    # Generate context-aware response using the tuvi query engine
    try:
        # Use the existing query engine for detailed questions
        response = query_engine.query(message)
        
        # Save assistant response
        save_chat_message(user_id, str(response), "assistant", ConversationState.CONSULTING)
        
        return str(response)
    except Exception as e:
        error_response = f"‚ùå C√≥ l·ªói x·∫£y ra khi x·ª≠ l√Ω c√¢u h·ªèi: {str(e)}"
        save_chat_message(user_id, error_response, "assistant", ConversationState.CONSULTING)
        return error_response

def prompt_to_predict(questionMessage='', user_id='default'):
    """Entry point for intelligent conversation flow"""
    return intelligent_conversation_flow(questionMessage, user_id)
